{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd0d8b7b-0d03-4d4f-99f3-702fff78cae5",
   "metadata": {},
   "source": [
    "### 添加未登录词(字)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18bcb34d-7d5b-4f59-8572-cef295b36531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4193, 1, 6821, 702, 782, 2582, 720, 3416, 8043]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "token = BertTokenizer.from_pretrained(\"./\")\n",
    "sentence = \"中核釱白怎么样？\"\n",
    "sentence = \"焦赟这个人怎么样？\"\n",
    "token.convert_tokens_to_ids(token.tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942e0cc-3699-4416-bb26-c7e99101e962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0abed170-4ee7-486a-930f-788c010bc569",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 未登录词(字)太多了，超过unused的个数   \n",
    "#### 评估一下未登录词(字)对任务的影响，如果影响很小的话，unused解决一部分，剩下的可以忽略不计；  \n",
    "#### 如果忽略这些未登录词(字)确实有很大影响的话，那就添加字典吧,并且同时修改权重参数尺寸，修改模型尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9675d9cd-8f9b-4975-929b-bc3b04d82925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4193, 21128, 6821, 702, 782, 2582, 720, 3416, 8043]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer,BertForMaskedLM,BertConfig,BertModel\n",
    "token = BertTokenizer.from_pretrained(\"./\")\n",
    "sentence = \"焦赟这个人怎么样？\"\n",
    "token.convert_tokens_to_ids(token.tokenize(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65d82154-bcaf-432f-a96f-93cee7a3a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_json_file(\"./config.json\")\n",
    "model = BertForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf851d1-1af4-4acf-a8cd-c1cd4f65f913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "699b46bb-dc66-434b-8414-6dd9df8239ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight = torch.load(\"./pytorch_model.bin\")\n",
    "# for item in [\"bert.embeddings.word_embeddings.weight\",\"cls.predictions.bias\",\"cls.predictions.decoder.weight\"]:\n",
    "#     del model_weight[item]\n",
    "\n",
    "for item in [\"bert.embeddings.word_embeddings.weight\",\"cls.predictions.bias\",\"cls.predictions.decoder.weight\"]:\n",
    "    model_weight[item] = torch.cat([model_weight[item],model_weight[item][0:1]],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f776d8cf-86b5-48f6-9a83-a9c3310ad8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21128, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_weight[\"bert.embeddings.word_embeddings.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413b9fcc-46ef-4fa0-abd6-22e9132937e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['bert.embeddings.position_ids', 'cls.predictions.decoder.bias'], unexpected_keys=['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_weight,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02fc76d9-9c5d-47d4-8607-647316aab8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21129, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_parameter(\"bert.embeddings.word_embeddings.weight\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971856fa-8649-4ff7-8f90-b60451e57474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29731af2-10d6-4d10-9c7c-7b71facc903d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 添加未登录词(词)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96ef1714-49b0-4c38-ae73-da7df5817828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['万', '里', '长', '城', '是', '世', '界', '七', '大', '奇', '迹', '之', '一']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import jieba\n",
    "import torch\n",
    "token = BertTokenizer.from_pretrained(\"./\")\n",
    "sentence = \"万里长城是世界七大奇迹之一\"\n",
    "token.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49612a77-bb64-4f49-ad9f-6286149f00bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['万里长城', '是', '世', '界', '七', '大', '奇', '迹', '之', '一']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.add_word(\"万里长城\")\n",
    "jieba.lcut(sentence)\n",
    "ls = jieba.lcut(sentence)\n",
    "ls = ls[0:1]+list(\"\".join(ls[1:]))\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b9b8924-da6a-466c-8185-9e12530a03e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 3221, 686, 4518, 673, 1920, 1936, 6839, 722, 671]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.convert_tokens_to_ids(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba7261-481e-4bf8-a62b-1d9a5a6051ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41b5b743-418f-4a45-98c2-4491b020be3a",
   "metadata": {},
   "source": [
    "### wwm(whole word mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9781de4c-c677-412b-8dff-ab19b4880261",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text           使用语言模型来预测下一个词的概率。\n",
    "CWS                使用 语言 模型 来 预测 下 一个 词 的 概率\n",
    "Original Masking   使 用 语 言 [M] 型 来 [M] 测 下 一 个 词 的 概 率\n",
    "WWM                使 用 语 言 [M] [M] 来 [M] [M] 下 一 个 词 的 概 率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a868cbf-40c5-4aaf-84fb-f2aa46e07852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['使',\n",
       " '用',\n",
       " '语',\n",
       " '言',\n",
       " '[MASK]',\n",
       " '[MASK]',\n",
       " '来',\n",
       " '预',\n",
       " '测',\n",
       " '下',\n",
       " '[MASK]',\n",
       " '[MASK]',\n",
       " '词',\n",
       " '的',\n",
       " '概',\n",
       " '率']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WWM\n",
    "import numpy as np\n",
    "sentence = \"使用语言模型来预测下一个词的概率\"\n",
    "sentence = jieba.lcut(sentence)\n",
    "mask_ids = np.random.choice(range(len(sentence)),2)\n",
    "wwm = []\n",
    "for i in range(len(sentence)):\n",
    "    if i in mask_ids:\n",
    "        wwm+=[\"[MASK]\"]*len(sentence[i])\n",
    "    else:\n",
    "        wwm+=list(sentence[i])\n",
    "wwm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7f58a572-fc57-4912-ac99-28e324246f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103,\n",
       " 103,\n",
       " 6427,\n",
       " 6241,\n",
       " 3563,\n",
       " 1798,\n",
       " 3341,\n",
       " 7564,\n",
       " 3844,\n",
       " 678,\n",
       " 103,\n",
       " 103,\n",
       " 6404,\n",
       " 4638,\n",
       " 3519,\n",
       " 4372]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11744cc7-9090-46a6-86a2-a6c4dde75f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
